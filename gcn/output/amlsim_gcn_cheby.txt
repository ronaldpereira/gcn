Calculating Chebyshev polynomials up to order 3...
Epoch: 0001 train_loss= 0.89437 train_acc= 0.36671 val_loss= 0.60136 val_acc= 0.99800 time= 30.07703
Epoch: 0002 train_loss= 0.65610 train_acc= 0.59067 val_loss= 0.45120 val_acc= 0.99800 time= 27.46974
Epoch: 0003 train_loss= 0.47101 train_acc= 0.83229 val_loss= 0.33155 val_acc= 0.99800 time= 29.33096
Epoch: 0004 train_loss= 0.33035 train_acc= 0.96641 val_loss= 0.24035 val_acc= 0.99800 time= 25.13788
Epoch: 0005 train_loss= 0.22683 train_acc= 0.99046 val_loss= 0.17397 val_acc= 0.99800 time= 28.14029
Epoch: 0006 train_loss= 0.15602 train_acc= 0.99530 val_loss= 0.12393 val_acc= 0.99800 time= 26.96702
Epoch: 0007 train_loss= 0.10940 train_acc= 0.99610 val_loss= 0.08528 val_acc= 0.99800 time= 27.79304
Epoch: 0008 train_loss= 0.07916 train_acc= 0.99622 val_loss= 0.06014 val_acc= 0.99800 time= 24.69442
Epoch: 0009 train_loss= 0.06008 train_acc= 0.99622 val_loss= 0.04420 val_acc= 0.99800 time= 25.01409
Epoch: 0010 train_loss= 0.04812 train_acc= 0.99621 val_loss= 0.03418 val_acc= 0.99800 time= 25.98302
Epoch: 0011 train_loss= 0.04082 train_acc= 0.99624 val_loss= 0.02788 val_acc= 0.99800 time= 24.81896
Epoch: 0012 train_loss= 0.03657 train_acc= 0.99622 val_loss= 0.02393 val_acc= 0.99800 time= 25.96182
Epoch: 0013 train_loss= 0.03403 train_acc= 0.99622 val_loss= 0.02146 val_acc= 0.99800 time= 25.54335
Epoch: 0014 train_loss= 0.03249 train_acc= 0.99624 val_loss= 0.01993 val_acc= 0.99800 time= 25.72980
Epoch: 0015 train_loss= 0.03182 train_acc= 0.99623 val_loss= 0.01899 val_acc= 0.99800 time= 27.28633
Epoch: 0016 train_loss= 0.03119 train_acc= 0.99623 val_loss= 0.01842 val_acc= 0.99800 time= 24.42771
Epoch: 0017 train_loss= 0.03115 train_acc= 0.99624 val_loss= 0.01807 val_acc= 0.99800 time= 26.34592
Epoch: 0018 train_loss= 0.03127 train_acc= 0.99624 val_loss= 0.01787 val_acc= 0.99800 time= 25.34484
Epoch: 0019 train_loss= 0.03171 train_acc= 0.99624 val_loss= 0.01776 val_acc= 0.99800 time= 25.72886
Epoch: 0020 train_loss= 0.03195 train_acc= 0.99624 val_loss= 0.01770 val_acc= 0.99800 time= 25.78924
Epoch: 0021 train_loss= 0.03263 train_acc= 0.99624 val_loss= 0.01767 val_acc= 0.99800 time= 24.69869
Epoch: 0022 train_loss= 0.03264 train_acc= 0.99624 val_loss= 0.01766 val_acc= 0.99800 time= 25.94879
Epoch: 0023 train_loss= 0.03262 train_acc= 0.99624 val_loss= 0.01765 val_acc= 0.99800 time= 24.62188
Epoch: 0024 train_loss= 0.03317 train_acc= 0.99624 val_loss= 0.01765 val_acc= 0.99800 time= 25.97389
Epoch: 0025 train_loss= 0.03310 train_acc= 0.99624 val_loss= 0.01764 val_acc= 0.99800 time= 26.43386
Epoch: 0026 train_loss= 0.03324 train_acc= 0.99624 val_loss= 0.01763 val_acc= 0.99800 time= 24.65052
Epoch: 0027 train_loss= 0.03349 train_acc= 0.99624 val_loss= 0.01761 val_acc= 0.99800 time= 26.03483
Epoch: 0028 train_loss= 0.03384 train_acc= 0.99624 val_loss= 0.01759 val_acc= 0.99800 time= 24.74847
Epoch: 0029 train_loss= 0.03362 train_acc= 0.99624 val_loss= 0.01756 val_acc= 0.99800 time= 25.40605
Epoch: 0030 train_loss= 0.03389 train_acc= 0.99624 val_loss= 0.01752 val_acc= 0.99800 time= 24.21266
Epoch: 0031 train_loss= 0.03390 train_acc= 0.99624 val_loss= 0.01747 val_acc= 0.99800 time= 25.41722
Epoch: 0032 train_loss= 0.03388 train_acc= 0.99624 val_loss= 0.01742 val_acc= 0.99800 time= 25.35615
Epoch: 0033 train_loss= 0.03387 train_acc= 0.99624 val_loss= 0.01736 val_acc= 0.99800 time= 24.42634
Epoch: 0034 train_loss= 0.03382 train_acc= 0.99624 val_loss= 0.01729 val_acc= 0.99800 time= 25.33859
Epoch: 0035 train_loss= 0.03380 train_acc= 0.99624 val_loss= 0.01723 val_acc= 0.99800 time= 25.40595
Epoch: 0036 train_loss= 0.03370 train_acc= 0.99624 val_loss= 0.01715 val_acc= 0.99800 time= 27.86592
Epoch: 0037 train_loss= 0.03342 train_acc= 0.99624 val_loss= 0.01707 val_acc= 0.99800 time= 26.77482
Epoch: 0038 train_loss= 0.03373 train_acc= 0.99624 val_loss= 0.01699 val_acc= 0.99800 time= 25.54781
Epoch: 0039 train_loss= 0.03332 train_acc= 0.99624 val_loss= 0.01691 val_acc= 0.99800 time= 25.55276
Epoch: 0040 train_loss= 0.03347 train_acc= 0.99624 val_loss= 0.01682 val_acc= 0.99800 time= 26.12200
Epoch: 0041 train_loss= 0.03331 train_acc= 0.99624 val_loss= 0.01673 val_acc= 0.99800 time= 25.75403
Epoch: 0042 train_loss= 0.03338 train_acc= 0.99624 val_loss= 0.01664 val_acc= 0.99800 time= 24.41685
Epoch: 0043 train_loss= 0.03308 train_acc= 0.99624 val_loss= 0.01655 val_acc= 0.99800 time= 25.61607
Epoch: 0044 train_loss= 0.03297 train_acc= 0.99624 val_loss= 0.01646 val_acc= 0.99800 time= 26.22520
Epoch: 0045 train_loss= 0.03256 train_acc= 0.99624 val_loss= 0.01635 val_acc= 0.99800 time= 25.84686
Epoch: 0046 train_loss= 0.03248 train_acc= 0.99624 val_loss= 0.01623 val_acc= 0.99800 time= 24.06288
Epoch: 0047 train_loss= 0.03201 train_acc= 0.99624 val_loss= 0.01609 val_acc= 0.99800 time= 26.93570
Epoch: 0048 train_loss= 0.03183 train_acc= 0.99624 val_loss= 0.01595 val_acc= 0.99800 time= 25.67606
Epoch: 0049 train_loss= 0.03155 train_acc= 0.99624 val_loss= 0.01581 val_acc= 0.99800 time= 24.92153
Epoch: 0050 train_loss= 0.03121 train_acc= 0.99624 val_loss= 0.01567 val_acc= 0.99800 time= 26.30458
Epoch: 0051 train_loss= 0.03100 train_acc= 0.99624 val_loss= 0.01555 val_acc= 0.99800 time= 24.69501
Epoch: 0052 train_loss= 0.03025 train_acc= 0.99624 val_loss= 0.01545 val_acc= 0.99800 time= 25.71933
Epoch: 0053 train_loss= 0.03009 train_acc= 0.99624 val_loss= 0.01540 val_acc= 0.99800 time= 24.83185
Epoch: 0054 train_loss= 0.02955 train_acc= 0.99624 val_loss= 0.01543 val_acc= 0.99800 time= 24.60378
Epoch: 0055 train_loss= 0.02936 train_acc= 0.99624 val_loss= 0.01556 val_acc= 0.99800 time= 27.11982
Epoch: 0056 train_loss= 0.02898 train_acc= 0.99624 val_loss= 0.01584 val_acc= 0.99800 time= 25.45949
Early stopping...
Optimization Finished!
Test set results: cost= 0.02668 accuracy= 0.99607 time= 10.80055
