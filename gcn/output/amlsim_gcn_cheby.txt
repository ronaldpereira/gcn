Calculating Chebyshev polynomials up to order 3...
Epoch: 0001 train_loss= 1.02220 train_acc= 0.24944 val_loss= 0.60094 val_acc= 1.00000 time= 1.85439
Epoch: 0002 train_loss= 0.76465 train_acc= 0.48422 val_loss= 0.44967 val_acc= 1.00000 time= 1.56028
Epoch: 0003 train_loss= 0.55696 train_acc= 0.77938 val_loss= 0.32862 val_acc= 1.00000 time= 1.53725
Epoch: 0004 train_loss= 0.39338 train_acc= 0.88404 val_loss= 0.23584 val_acc= 1.00000 time= 1.49695
Epoch: 0005 train_loss= 0.27226 train_acc= 0.98426 val_loss= 0.16714 val_acc= 1.00000 time= 1.68970
Epoch: 0006 train_loss= 0.18597 train_acc= 0.99584 val_loss= 0.11573 val_acc= 1.00000 time= 1.59443
Epoch: 0007 train_loss= 0.13063 train_acc= 0.99602 val_loss= 0.08022 val_acc= 1.00000 time= 1.62246
Epoch: 0008 train_loss= 0.09222 train_acc= 0.99604 val_loss= 0.05618 val_acc= 1.00000 time= 1.50866
Epoch: 0009 train_loss= 0.06707 train_acc= 0.99604 val_loss= 0.03928 val_acc= 1.00000 time= 1.50712
Epoch: 0010 train_loss= 0.05332 train_acc= 0.99607 val_loss= 0.02705 val_acc= 1.00000 time= 1.54072
Epoch: 0011 train_loss= 0.04386 train_acc= 0.99597 val_loss= 0.01929 val_acc= 1.00000 time= 1.51928
Epoch: 0012 train_loss= 0.03885 train_acc= 0.99607 val_loss= 0.01430 val_acc= 1.00000 time= 1.52080
Epoch: 0013 train_loss= 0.03593 train_acc= 0.99607 val_loss= 0.01104 val_acc= 1.00000 time= 1.66047
Epoch: 0014 train_loss= 0.03325 train_acc= 0.99609 val_loss= 0.00885 val_acc= 1.00000 time= 1.59200
Epoch: 0015 train_loss= 0.03248 train_acc= 0.99609 val_loss= 0.00733 val_acc= 1.00000 time= 1.53406
Epoch: 0016 train_loss= 0.03214 train_acc= 0.99609 val_loss= 0.00625 val_acc= 1.00000 time= 1.58639
Epoch: 0017 train_loss= 0.03254 train_acc= 0.99607 val_loss= 0.00545 val_acc= 1.00000 time= 1.59792
Epoch: 0018 train_loss= 0.03182 train_acc= 0.99609 val_loss= 0.00485 val_acc= 1.00000 time= 1.61897
Epoch: 0019 train_loss= 0.03273 train_acc= 0.99609 val_loss= 0.00437 val_acc= 1.00000 time= 1.64575
Epoch: 0020 train_loss= 0.03265 train_acc= 0.99607 val_loss= 0.00399 val_acc= 1.00000 time= 1.51532
Epoch: 0021 train_loss= 0.03269 train_acc= 0.99602 val_loss= 0.00367 val_acc= 1.00000 time= 1.62914
Epoch: 0022 train_loss= 0.03410 train_acc= 0.99609 val_loss= 0.00341 val_acc= 1.00000 time= 1.52029
Epoch: 0023 train_loss= 0.03400 train_acc= 0.99609 val_loss= 0.00318 val_acc= 1.00000 time= 1.61044
Epoch: 0024 train_loss= 0.03424 train_acc= 0.99609 val_loss= 0.00298 val_acc= 1.00000 time= 1.68074
Epoch: 0025 train_loss= 0.03557 train_acc= 0.99607 val_loss= 0.00281 val_acc= 1.00000 time= 1.58822
Epoch: 0026 train_loss= 0.03550 train_acc= 0.99609 val_loss= 0.00266 val_acc= 1.00000 time= 1.70016
Epoch: 0027 train_loss= 0.03493 train_acc= 0.99609 val_loss= 0.00252 val_acc= 1.00000 time= 1.77415
Epoch: 0028 train_loss= 0.03516 train_acc= 0.99609 val_loss= 0.00240 val_acc= 1.00000 time= 1.78647
Epoch: 0029 train_loss= 0.03593 train_acc= 0.99609 val_loss= 0.00230 val_acc= 1.00000 time= 1.58346
Epoch: 0030 train_loss= 0.03591 train_acc= 0.99609 val_loss= 0.00220 val_acc= 1.00000 time= 1.56412
Epoch: 0031 train_loss= 0.03631 train_acc= 0.99609 val_loss= 0.00212 val_acc= 1.00000 time= 1.61959
Epoch: 0032 train_loss= 0.03592 train_acc= 0.99609 val_loss= 0.00204 val_acc= 1.00000 time= 1.63312
Epoch: 0033 train_loss= 0.03582 train_acc= 0.99609 val_loss= 0.00197 val_acc= 1.00000 time= 1.59555
Epoch: 0034 train_loss= 0.03579 train_acc= 0.99609 val_loss= 0.00191 val_acc= 1.00000 time= 1.56634
Epoch: 0035 train_loss= 0.03489 train_acc= 0.99609 val_loss= 0.00186 val_acc= 1.00000 time= 1.57414
Epoch: 0036 train_loss= 0.03653 train_acc= 0.99609 val_loss= 0.00181 val_acc= 1.00000 time= 1.54197
Epoch: 0037 train_loss= 0.03575 train_acc= 0.99609 val_loss= 0.00177 val_acc= 1.00000 time= 1.58230
Epoch: 0038 train_loss= 0.03581 train_acc= 0.99609 val_loss= 0.00174 val_acc= 1.00000 time= 1.48056
Epoch: 0039 train_loss= 0.03663 train_acc= 0.99609 val_loss= 0.00171 val_acc= 1.00000 time= 1.63511
Epoch: 0040 train_loss= 0.03496 train_acc= 0.99609 val_loss= 0.00169 val_acc= 1.00000 time= 1.64300
Epoch: 0041 train_loss= 0.03528 train_acc= 0.99609 val_loss= 0.00167 val_acc= 1.00000 time= 1.54220
Epoch: 0042 train_loss= 0.03520 train_acc= 0.99609 val_loss= 0.00166 val_acc= 1.00000 time= 1.57622
Epoch: 0043 train_loss= 0.03419 train_acc= 0.99609 val_loss= 0.00165 val_acc= 1.00000 time= 1.56872
Epoch: 0044 train_loss= 0.03408 train_acc= 0.99609 val_loss= 0.00165 val_acc= 1.00000 time= 1.49131
Epoch: 0045 train_loss= 0.03422 train_acc= 0.99609 val_loss= 0.00166 val_acc= 1.00000 time= 1.58711
Epoch: 0046 train_loss= 0.03382 train_acc= 0.99609 val_loss= 0.00168 val_acc= 1.00000 time= 1.55840
Epoch: 0047 train_loss= 0.03364 train_acc= 0.99609 val_loss= 0.00171 val_acc= 1.00000 time= 1.55047
Early stopping...
Optimization Finished!
Test set results: cost= 0.03461 accuracy= 0.99568 time= 0.64624
F1-Score of non-Frauds: 0.888884
F1-Score of Frauds: 0.000000
F1-Score macro: 0.444442
